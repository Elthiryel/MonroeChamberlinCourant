\chapter{Implemented Algorithms}
\label{cha:implementedAlgorithms}

In this chapter we present implemented algorithms for the utilitarian versions of Monroe and Chamberlin-Courant multiwinner voting rules in the satisfaction-based framework.
\\

\noindent
\textbf{Proposition 1 (Implicit in the paper of Betzler et al. \cite{3}).} Let $\alpha$ be a normal DPSF, $N$ be a set of agents, $A$ be a set of alternatives, $V$ be a preference profile of $N$ over $A$, and $S$ a $K$-element subset of $A$ (where $K$ divides $\norm{N}$). Then there is a polynomial-time-algorithm that computes a (possibly partial) optimal K-assignment $\Phi^{S}_{\alpha}$ (Monroe K-assignment $\Phi^{S}_{\alpha}$) of the agents to the alternatives from $S$.
\\

\section{Algorithm A}

Algorithm A was first presented by Skowron et al. \cite{1} and tries to solve $\alpha$-Monroe-SatWinner. It builds a solution iteratively (greedily). In each step we pick some not-yet-assigned alternative $a_{i}$ and assign it to those $\frac{N}{K}$ agents that are not assigned to any other alternative yet and whose satisfaction of being matched with $a_{i}$ is maximal (criterion for picking an alternative in each step is a sum of satisfaction of agents selected this way). This algorithm runs in polynomial time \cite{1}. Pseudocode is presented in Algorithm 1.

\begin{algorithm}
\caption{Algorithm A}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeMonroeSatWinner}{}
		\State $\Phi \gets$ a map defining a partial assignment, iteratively built by the algorithm
		\State $\Phi^{\leftarrow} \gets$ the set of agents for which the assignment is already defined
		\State $\Phi^{\rightarrow} \gets$ the set of alternatives already used in the assignment
		\If {$K \leq 2$}
			\State compute the optimal solution using an algorithm of Betzler et al. \cite{1} and return
		\EndIf
		\State $\Phi$ = $\{\}$
		\For{$i \gets 1$ to $K$}
			\State $score \gets \{\}$
			\State $bests \gets \{\}$
			\ForAll{$a_{i} \in A \setminus \Phi^{\rightarrow}$}
				\State $agents \gets$ sort $N \setminus \Phi^{\leftarrow}$ so that if agent $j$ preceeds agent $j'$ then $pos_{j}(a_{i}) \leq pos_{j'}(a_{i})$
				\State $bests[a_{i}] \gets$ choose first $\frac{N}{K}$ elements from $agents$
				\State $score[a_{i}] \gets \sum_{j \in bests[a_{i}]}(m - pos_{j}(a_{i}))$
			\EndFor
			\State $a_{best} \gets argmax_{a \in A \setminus \Phi^{\rightarrow}} score[a]$
			\ForAll{$j \in bests[a_{best}]$}
				\State $\Phi[j] \gets a_{best}$
			\EndFor
		\EndFor
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Algorithm B}

Algorithm B is an extension to Algorithm A and was presented in the same paper. The idea is to run Algorithm A first and then optimally reassign the alternatives to the voters (using Proposition 1). It should noticeably improve the results of the algorithm and it still runs in polynomial time.

\section{Algorithm C}

Algorithm C is a further extension to Algorithm B, also presented by Skowron et al. \cite{1}. While Algorithm B only keeps one partial assignment function $\Phi$ that is extended in each step until it becomes a full assignment, Algorithm C stores a list of $d$ functions ($d$ is provided as an algorithm parameter). At each step, for each alternative $a$ with no agent assigned and for each $\Phi$ of the $d$ functions stored, we compute an extension to $\Phi$ that assigns $\frac{N}{K}$ agents (that are not assigned to any other alternative yet) to $a$ (the same way as in Algorithm A). For the next step, $d$ functions that give the highest satisfaction are kept. If we take $d = 1$, we obtain Algorithm B. Pseudocode is presented in Algorithm 3.
\\

Unlike previous algorithms, Algorithm C can be used for both Monroe and Chamberlin-Courant rules. To adapt it to the Chamberlin-Courant rule, we have to replace the contents of the first for all loop with the appropriate code, presented in Algorithm 2.

\begin{algorithm}
\caption{Algorithm C - CC for all code replacement}\label{euclid}
\begin{algorithmic}[1]
	\ForAll{$a_{i} \in A \setminus \Phi^{\rightarrow}$}
		\State $\Phi' \gets \Phi$
		\ForAll{$j \in N$}
			\If{agent $j$ prefers $a_{i}$ to $\Phi'(j)$}
				\State $\Phi'(j) \gets a_{i}$
			\EndIf
		\EndFor
		\State $newPar.push(\Phi')$
	\EndFor
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Algorithm C}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeMonroeSatWinner}{}
		\State $\Phi \gets$ a map defining a partial assignment, iteratively built by the algorithm
		\State $\Phi^{\leftarrow} \gets$ the set of agents for which the assignment is already defined
		\State $\Phi^{\rightarrow} \gets$ the set of alternatives already used in the assignment
		\State $Par \gets$ a list of partial representation functions
		\State $Par = []$
		\State $Par.push(/{/})$
		\For{$i \gets 1$ to $K$}
			\State $newPar = []$
			\For{$\Phi \in Par$}
				\State $bests \gets \{\}$
				\ForAll{$a_{i} \in A \setminus \Phi^{\rightarrow}$}
					\State $agents \gets$ sort $N \setminus \Phi^{\leftarrow}$ (agent $j$ preceeds agent $j'$ implies that $pos_{j}(a_{i}) \leq pos_{j'}(a_{i})$
					\State $bests[a_{i}] \gets$ choose first $\frac{N}{K}$ elements of $agents$
					\State $\Phi' \gets \Phi$
					\ForAll{$j \in bests[a_{i}]$}
						\State $\Phi'[j] \gets a_{i}$
					\EndFor
					\State $newPar.push(\Phi')$
				\EndFor
			\EndFor
			\State sort $newPar$ according to descending order of the total satisfaction of the assigned agents
			\State $Par \gets$ choose first $d$ elements of $newPar$
		\EndFor
		\For{$\Phi \in Par$}
			\State $\Phi \gets$ compute the optimal representative function using an algorithm of Betzler et al. \cite{3} for the set of winners $\Phi^{\rightarrow}$
		\EndFor
		\State \Return the best representative function from $Par$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Algorithm R}

As shown by Skowron et al. \cite{1}, algorithms A, B and C achieve very high approximations ratios under linear satisfaction function for the cases where $K$ is small relative to $m$. For the other cases, we can use a sampling-based randomized algorithm (called Algorithm R). We expect that under nonlinear satisfaction function algorithms should behave similarly in relation to each other as under a linear one.
\\

Algorithm R randomly picks $K$ alternatives and then, using Proposition 1, assigns them to agents optimally. As such an algorithm may be simply unlucky and pick alternatives that are ranked low, random assignment should be computed a given number of times (which is provided as a parameter), so there is a greater probability to attain a high quality solution. If $K$ is comparable to $m$ then it is likely that generated results would include a solution that is at least close to optimal. Algorithm can naturally be used for both Monroe and Chamberlin-Courant systems.

\section{Algorithm AR}

Algorithm family A-C and Algorithm R are naturally suitable for different cases. Therefore, Skowron et al. \cite{1} proposed to combine algorithms A and R into Algorithm AR. They also showed that under linear satisfaction function, Algorithm AR can achieve approximation ratio of $0.715 - e$ with probability $\lambda$. Both $e$ and $\lambda$ are provided as algorithm parameters. Naturally, for different satisfaction functions approximation ratio may vary, but we decided to test the algorithm in an unchanged version for comparison. Pseudocode is presented in Algorithm 4.

\begin{algorithm}
\caption{Algorithm AR}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeMonroeSatWinner}{}
		\State $H_{j}$ is the $j$'th harmonic number $H_{j} = \sum_{i=1}^{j}(\frac{1}{i})$
		\State $\lambda \gets$ probability of achieving the approximation ratio $0.715 - e$ under linear satisfaction function
		\If{$\frac{H_{K}}{K} \geq \frac{e}{2}$}
			\State compute the optimal solution using an algorithm of Betzler et al. \cite{3} and return
		\EndIf
		\If{$m \leq 1 + \frac{2}{e}$}
			\State compute the optimal solution using a simple brute force algorithm and return
		\EndIf
		\State $\Phi_{1} \gets$ solution computed by Algorithm A
		\State $\Phi_{2} \gets$ solution computed by Algorithm R (sampled $\log (1 - \lambda) \cdot \frac{2 + e}{e}$ times)
		\State \Return the better assignment among $\Phi_{1}$ and $\Phi_{2}$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Algorithm GM}

Algorithm GM (greedy marginal improvement) is an algorithm that was introduced by Lu and Boutilier \cite{4} for the Chamberlin-Courant rule only. However, it was later generalized by Skowron et al. \cite{1}, so it can be applied to the Monroe rule as well. In the Monroe case, it can be considered as the Algorithm B improvement.
\\

We start with an empty set $S$. In each iteration of the algorithm we select an alternative $a$ that is not assigned to agents yet, and that maximizes the satisfaction value $l_{sum}^{\alpha}(\Phi^{S \cup \{a\}}_{\alpha})$. Iterations are executed until a complete committee is selected, so $K$ iterations are required. For Monroe case, computing $\Phi^{S}_{\alpha}$ is slow (it is achieved by using min-cost/max-flow algorithm \cite{3}), which makes the algorithm execute for a relatively long time. Pseudocode is presented in Algorithm 5.
\\

Algorithm GM is an $1-\frac{1}{e}$-approximation algorithm for any normal IPSF \cite{1,5}.

\begin{algorithm}
\caption{Algorithm GM}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeSatWinner}{}
		\State $\Phi^{S}_{\alpha}$ - the partial assignment that assigns a single alternative to at most $\frac{n}{K}$ agents, that assigns to the agents only the alternatives from $S$, and that maximizes the utilitarian satisfaction $l^{\alpha}_{sum}(\Phi^{S}_{\alpha})$
		\State $S \gets \emptyset$
		\For{$i \gets 1$ to $K$}
			\State $a \gets argmax_{a \in A \setminus S} l^{\alpha}_{sum} (\Phi^{S \cup \{\alpha\}}_{\alpha})$
			\State $S \gets S \cup \{a\}$
		\EndFor
		\State \Return $\Phi^{S}_{\alpha}$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Algorithm P}

Algorithm P can only be applied to Chamberlin-Courant problem. It was first introduced by Skowron et al. \cite{1}. In the beginning, it computes $x$ (a non-negative integer). Next, it computes an assignment that should maximize the number of agents that have an alternative from the first $x$ spots in their preferences assigned to them. This process is executed greedily. Afterwards, if there are still agents with no alternative assigned, the best alternative is picked from the ones already selected for at least one other agent.
\\

$w(x)$ used in the algorithm is a Lambert's W-function, defined to be the solution of the equation $x = w(x)e^{w(x)}$. Algorithm runs in polynomial time. Pseudocode of Algorithm P is presented in Algorithm 6.

\begin{algorithm}
\caption{Algorithm P}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeCCSatWinner}{}
		\State $\Phi \gets$ a map defining a partial assignment, iteratively built by the algorithm
		\State $\Phi^{\leftarrow} \gets$ the set of agents for which the assignment is already defined
		\State $\Phi^{\rightarrow} \gets$ the set of alternatives already used in the assignment
		\State $num\_pos_{x}(a) \gets \norm{\left\{ i \in [n] \setminus \Phi^{\leftarrow} : pos_{i}(a) \leq x \right\}}$ - the number of not-yet assigned agents that rank alternative $a$ in one of their first $x$ positions
		\State $w(\cdot)$ - Lambert's W-function
		\State $\Phi = \{\}$
		\State $x = \left\lceil \frac{mw(K)}{K} \right\rceil$
		\For{$i \gets 1$ to K}
			\State $a_{i} \gets argmax_{a \in A \setminus \Phi^{\rightarrow}} num\_pos_{x}(a)$
			\ForAll{$j \in [n] \setminus \Phi^{\leftarrow}$}
				\If{$pos_{j}(a_{i}) < x$}
					\State $\Phi[j] \gets a_{i}$
				\EndIf
			\EndFor
		\EndFor
		\ForAll{$j \in A \setminus \Phi^{\leftarrow}$}
			\State $a \gets$ such alternative from $\Phi^{\rightarrow}$ that $\forall_{a' \in \Phi^{\rightarrow}} pos_{j}(a) \leq pos_{j}(a')$
			\State $\Phi[j] \gets a$
		\EndFor
		\State \Return $\Phi$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Genetic Algorithm}

The idea of our algorithm is loosely based on metaheuristic genetic algorithms, such as the Firefly Algorithm \cite{6}.
\\

Our Genetic Algorithm starts with an initial set of creatures (each of them presenting a possible solution under Chamberlin-Courant or Monroe rule) which are later mutated and crossed over with each other. The best creatures (ones with the highest total satisfaction) are preferred for further mutation and crossover in order to better investigate the neighbourhood of local maxima, but on the other hand algorithm also produces new creatures by crossing over random existing ones to better explore entire solution space, not limiting to local extrema.
\\

In each iteration of the algorithm creatures are evaluated (satisfaction is computed). Best creature in terms of total satisfaction is compared with currently best found creature and takes its place if it is better. Half of the evaluated creatures (the best ones) are chosen for further propagation. Each of them is then mutated randomly. Remaining creatures are created by crossing over random creatures from the "better" half with each other. Resulting set of creatures is used for the next iteration. Number of iterations and number of creatures are the algorithm parameters. Pseudocode is presented in Algorithm 7.

\begin{algorithm}
\caption{Genetic Algorithm}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeCCSatWinner}{}
		\State $I$ - number of iterations
		\State $c$ - number of creatures
		\State $\Phi_{best}$ - best creature (preference profile)
		\State $creatures \gets$ generate initial random set of $c$ creatures
		\For{$i \gets 1$ to I}
			\State $creaturesSorted \gets$ sort $creatures$ by total satisfaction
			\If{$satisfaction(creaturesSorted[1]) > satisfaction(\Phi_{best})$}
				\State $\Phi_{best} = creaturesSorted[1]$
			\EndIf
			\State $bestCreatures \gets$ choose first $c/2$ elements from $creaturesSorted$
			\State $mutated \gets$ mutate all creatures from $bestCreatures$ randomly
			\State $crossed \gets$ crossover random creatures from $bestCreatures$ to produce $c/2$-element set
			\State $newCreatures \gets mutated \cup crossed$
			\State $creatures \gets newCreatures$
		\EndFor
		\State \Return $\Phi_{best}$
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\section{Simulated Annealing}

The Simulated Annealing algorithm is inspired by physical annealing process, used in metallurgy. It involves heating and cooling a material to make it attain specific physical properties. Using simulated annealing for optimization of a complex function depending on many parameters was proposed by Kirkpatrick et al. \cite{7}. We adapt it to the Chamberlin-Courant and Monroe problems.
\\

In simulated annealing we use a temperature variable, which has a high value at the beginning and gets lower ('cools') during the execution. When the temperature is high, algorithm can accept solutions worse than the current one more frequently, so it is possible to leave a local optimum, as the global one may be in totally different area of the search space. When the temperature gets lower, algorithm focuses on the area where solution close to the optimum may lie.
\\

To decide if the new solution should be accepted, the \textit{acceptance function} is used. If the new solution is better, it is always accepted. If it is worse, acceptance function accepts the new solution with probability $p$, which is calculated as follows:
\begin{gather}
	p = \exp(\frac{E_{c}-E_{n}}{T})
\end{gather}
$E_{c}$ is the current solution energy, $E_{n}$ is the new solution energy and $T$ is the temperature. Energy represents quality of the solution and, in our case, is proportional to the total satisfaction value of the solution.
\\

The algorithm proceeds as follows. First, it generates a random initial solution. Initial temperature is given as a parameter. Then, in each iteration, a new solution is generated by replacing one of the winners in the current solution with a random alternative that is not a winner in the current solution. The newly created solution is then evaluated by the acceptance function. If it is accepted, it replaces the current solution. Otherwise, the current solution is kept. For the next iteration, temperature is decreased:
\begin{gather}
	T \gets T \cdot (1 - c)
\end{gather}
$c$ is the cooling rate, provided as a parameter. The algorithm stops when $T \leq 1$. Pseudocode is presented in Algorithm 8.

\begin{algorithm}
\caption{Simulated Annealing}\label{euclid}
\begin{algorithmic}[1]
	\Procedure{ComputeCCSatWinner}{}
		\State $T_{start}$ - initial temperature
		\State $c$ - cooling rate
		\State $\Phi_{curr}$ - current solution
		\State $T$ - current temperature
		\State $E(\Phi)$ - energy of solution $\Phi$
		\State $\Phi_{curr} \gets$ generate initial random solution
		\State $T \gets T_{start}$
		\While{$T > 1$}
			\State $\Phi_{new} \gets$ perform random replacement on $\Phi_{curr}$
			\State $p \gets \exp(\frac{E(\Phi_{curr})-E(\Phi_{new})}{T})$
			\State $r \gets$ generate random number in range $[0;1)$
			\If{$E(\Phi_{new}) > E(\Phi_{curr})$ or $p > r$}
				\State $\Phi_{curr} \gets \Phi_{new}$
			\EndIf
			\State $T \gets T \cdot (1 - c)$
		\EndWhile
		\State \Return $\Phi_{curr}$
	\EndProcedure
\end{algorithmic}
\end{algorithm}
